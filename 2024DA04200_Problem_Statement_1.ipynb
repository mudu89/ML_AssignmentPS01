{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mudu89/ML_AssignmentPS01/blob/main/2024DA04200_Problem_Statement_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJFpa_1haflG",
        "outputId": "24405e0e-ef18-4d30-f399-00c1d6e63108"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ML_Assignment_01/ML_AssignmentPS01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQx4wlE5d5S5",
        "outputId": "59d59bbb-9ea4-4c54-95d6-d7e0c688fd2a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/ML_Assignment_01/ML_AssignmentPS01'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Importing the dataset:**\n",
        "\n",
        "Read the dataset from the path into a pandas dataframe."
      ],
      "metadata": {
        "id": "9m94QL8lde8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "dataset_file = './risk_factors_cervical_cancer.csv'\n",
        "\n",
        "df = pd.read_csv(dataset_file)"
      ],
      "metadata": {
        "id": "yraP2t69divG",
        "outputId": "804f6c06-1f07-4277-a2de-13dc2c153578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './risk_factors_cervical_cancer.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-430270945.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdataset_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./risk_factors_cervical_cancer.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './risk_factors_cervical_cancer.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Data Exploration and Analysis:**\n",
        "\n",
        "In this section, we will perform exploratory analysis of the dataset to get insight of the data, and understand the correlation of the variables.\n",
        "\n",
        "We will also identify if the correlation analysis helps in the feature selection process."
      ],
      "metadata": {
        "id": "mx4gcmhJeTRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "print(\"The shape of the given dataset is:\", df.shape)\n",
        "print(\"Sanity Check:\")\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "ydHb7TbLeWL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ILGA_v32ofSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a total of 35 attributes and 1 target variable in the dataset. There are mix of numeric and categorical data.\n",
        "\n",
        "10 attributes are numeric and 26 are categorical.\n",
        "\n",
        "We can group the columns into :\n",
        "  \n",
        "  a) Demographic data: Age, Number of sexual partners, First Sexual intercourse, number of pregnancies.\n",
        "\n",
        "  b) Behavorial data: Smokes, Contraceptive usage.\n",
        "\n",
        "  c) Medical history data: STDs, Cancer, CIN, HPV.\n",
        "  \n",
        "  d) Diagnosis data: Hinselmann, Schiller, Citology, Biopsy"
      ],
      "metadata": {
        "id": "MAshvSIkkdD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1. Univariate Analysis (Categorical Attributes):**\n",
        "\n",
        "In this section, we will perform analysis of the categorical attributes to get more insights on their data."
      ],
      "metadata": {
        "id": "Frj5WDwrsgoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(exclude=['int64'])"
      ],
      "metadata": {
        "id": "Kgmr148l0aUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above table, we can identify that majority of the attributes are having 3 or less unique values.\n",
        "\n",
        "Also the frequency of the top value for such attributes is more than 70% of the total count.\n",
        "\n"
      ],
      "metadata": {
        "id": "rtKy0Uy0zC9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4,3))\n",
        "df['Biopsy'].value_counts(normalize=True).plot(kind='bar', color=['skyblue', 'salmon'])\n",
        "plt.title('Biopsy Class Balance (0=No Cancer, 1=Cancer)')\n",
        "plt.ylabel('Proportion')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "REOiqTsT39U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a very high class imbalance on the target variable."
      ],
      "metadata": {
        "id": "HybzLQ6irzxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, a = plt.subplots(15, 2, figsize=(18, 55))\n",
        "fig.tight_layout(pad=6.0)\n",
        "fig.align_titles()\n",
        "fig.suptitle('Univariate Analysis of Categorical Attributes',y=1.0,va='top',fontsize=20)\n",
        "\n",
        "axes = a.flatten()\n",
        "gs = axes[0].get_gridspec()\n",
        "\n",
        "\n",
        "sbplt_barh = 0\n",
        "full_width_row = 11\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "  # Select the current axis\n",
        "  if df[col].nunique() <= 25:\n",
        "    kind = 'bar'\n",
        "    ax = axes[sbplt_barh]\n",
        "    sbplt_barh += 1\n",
        "  else:\n",
        "    kind = 'bar'\n",
        "    axes[full_width_row * 2].remove()\n",
        "    axes[full_width_row * 2 + 1].remove()\n",
        "    ax = fig.add_subplot(gs[full_width_row, :])\n",
        "    full_width_row += 1\n",
        "\n",
        "  # # Use the selected axis\n",
        "  df[col].value_counts(normalize=False).sort_values(ascending=True).plot(ax=ax, kind=kind, rot=0)\n",
        "  ax.set_title(col) # Set title for clarity\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xugKJiDR9cDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first sexual encounter chart shows that majority of the participants had their first encounter below the age of 16 and the number of partners chart indicates maximum participants had less than 3.\n",
        "\n",
        "The bar chart for number of pregnancies shows that most women in the dataset\n",
        "have between 1 and 3 pregnancies, with very few having more than 6.\n",
        "\n",
        "The smoking status chart indicates that non-smokers form the majority, suggesting smoking is less common in this group.\n",
        "\n",
        "The STDS, IUD and Hormanal contraceptives indicate high volume of 0 and '?' values."
      ],
      "metadata": {
        "id": "EPcQUrmPG9Xr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2: Univariate analysis of Numeric data:**\n",
        "\n",
        "In this section, we will perform analysis of the numeric attributes to get more insights on their data."
      ],
      "metadata": {
        "id": "C4zcKtNAkuXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(exclude='object')"
      ],
      "metadata": {
        "id": "89-0e5Y6ktul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above table, we can see that the highest age is 84 and lowest is 13 with mean of 26. This indicates a spread of different age groups in the dataset."
      ],
      "metadata": {
        "id": "nc_WPoDUGK7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, a = plt.subplots(5, 5, figsize=(18, 18))\n",
        "fig.tight_layout(pad=6.0)\n",
        "fig.align_titles()\n",
        "fig.suptitle('Univariate Analysis of Numeric Attributes',y=1.0,va='top',fontsize=20)\n",
        "\n",
        "axes = a.flatten()\n",
        "# gs = axes[0].get_gridspec()\n",
        "\n",
        "\n",
        "# sbplt_barh = 0\n",
        "# full_width_row = 11\n",
        "for index, col in enumerate(df.select_dtypes(include='int64').columns):\n",
        "  ax=axes[index]\n",
        "  df[col].plot(kind='hist', ax=ax)\n",
        "  ax.set_title(col) # Set title for clarity\n",
        "\n",
        "num_of_attributes = (df.dtypes == 'int64').sum()\n",
        "for ax in axes[num_of_attributes:]:\n",
        "  fig.delaxes(ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UUGHgULjlmAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The age histogram is right-skewed, with a concentration of women in their late 20s to early 40s and fewer older participants.  \n",
        "Other numeric medical test results appear heavily zero-inflated, reflecting that many participants did not exhibit those conditions."
      ],
      "metadata": {
        "id": "Tc7MgyDdJO5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3: Bivariate Analysis with the target variable:**"
      ],
      "metadata": {
        "id": "5N42eG1-p75u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen in the univarte analysis, all the categorical attributes are having numbers as strings. Hence, we can convert all those attributes into numbers and perform a single correlation analysis using heatmap.\n",
        "\n",
        "To perform correlation analysis using a heatmap, we need to convert all relevant columns to a numeric data type. The object type columns that contain '?' as a value need to be handled. I will replace '?' with NaN (Not a Number) and then convert these columns to a numeric type. NaN values are standard representations for missing data in pandas and can be handled appropriately in subsequent steps."
      ],
      "metadata": {
        "id": "86dfw-UrxUqj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e92c79b9"
      },
      "source": [
        "df_copy = df.copy()\n",
        "\n",
        "for col in df_copy.select_dtypes(include='object').columns:\n",
        "    df_copy[col] = df_copy[col].replace('?', np.nan)\n",
        "    df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
        "\n",
        "display(df_copy.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation with target variable\n",
        "corr_target = df_copy.corr(numeric_only=True)['Biopsy'].sort_values(ascending=False)\n",
        "print(\"Correlation of features with Biopsy:\")\n",
        "print(corr_target)\n"
      ],
      "metadata": {
        "id": "vnls4QEe4hWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "625917cb"
      },
      "source": [
        "#plt.figure(figsize=(20, 15))\n",
        "corr_matrix = df_copy.corr()\n",
        "f, ax = plt.subplots(figsize=(20, 20))\n",
        "f.suptitle('Correlation Heatmap',y=0.92,va='top',fontsize=20)\n",
        "sns.heatmap(corr_matrix, annot=False, cmap='OrRd', ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Inference and Conclusion:***\n",
        "\n",
        "Correlation helps spot strong linear relationships with the target.\n",
        "\n",
        "Based on the heatmap and correlation analysis, we can identify correlation with the target variable as below:\n",
        "\n",
        "*    Top correlated features with Biopsy are Schiller (0.73), Hinselmann (0.55), Citology (0.33)\n",
        "*   Many STD-related features have weak correlations (below 0.15).\n",
        "*   Age, Contraceptive choice, and sexual preferences seem to have very neglibile correlation with the target.\n",
        "*   Several columns have NaN correlations due to constant values (e.g., STDs:AIDS always 0).\n",
        "\n",
        "Effect on feature selection:\n",
        "\n",
        "Strongly correlated features like Schiller, Hinselmann, and Citology are prime candidates to keep.\n",
        "\n",
        "Weakly correlated ones may still hold value in non-linear models (like Decision Trees or Ensemble Methods), so we shouldn’t remove them solely based on correlation.\n",
        "\n",
        "Features with almost no variance or with excessive missing values might be removed in preprocessing to reduce noise.\n",
        "\n",
        "Strong correlation between independent variables themselves (multicollinearity) can reduce the stability of coefficients in linear models, even if each variable is useful individually.  \n",
        "Example : STD's and STDs:Number of Diagnosis,\n",
        "Dx: Cancer and Dx: HPV\n",
        "  \n",
        "**Conclusion:** Correlation analysis is a useful guide for identifying potentially important features and for spotting redundancy, but it should be combined with domain knowledge and other feature selection methods before making final decisions."
      ],
      "metadata": {
        "id": "a4t8rcA95z9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Data Preprocessing and Cleaning:**\n",
        "\n",
        "In the previous section, we performed and identified the insights of the data attributes.\n",
        "\n",
        "Based on the univariate analysis, we can now proceed to cleanup the data and perform preprocessing steps like:\n",
        "\n",
        "a) NULL processing\n",
        "\n",
        "b) Missing values cleanup\n",
        "\n",
        "c) Managing skwed data\n",
        "\n",
        "d) Identifying and processing outliers\n",
        "\n",
        "e) Feature selection after data preprocessing. etc..."
      ],
      "metadata": {
        "id": "UWFartL_DjDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1. Handling missing/null values and data transformation:**\n",
        "\n",
        "From the univarite analysis, the categorical attributes are numbers and can be converted to numeric datatype.\n",
        "\n",
        "We will replace the '?' values with NaN before converting all attributes to numeric.\n",
        "\n",
        "We can handle the missing and NaN values by replacing them with the median value for the numeric attributes.\n",
        "\n",
        "Justification: The median is chosen because it is less influenced by extreme values compared to the mean, which makes it more robust when data is skewed.\n"
      ],
      "metadata": {
        "id": "c_UxWCvNKPKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace '?' with NaN and transform objects to numeric datatype:\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    df[col] = df[col].replace('?', np.nan)\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Check for isnull/isna\n",
        "print(\"Check for null values:\")\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "w9mJgntPU9P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = df.columns\n",
        "df[cols] = df[cols].fillna(df[cols].median())\n",
        "df.sample(5, random_state=42)"
      ],
      "metadata": {
        "id": "zUWxZqe1KKmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for null after preprocessing:\n",
        "print(\"Check for null values:\")\n",
        "print(df.isna().sum())"
      ],
      "metadata": {
        "id": "JvRmvsKxWb0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2: Outlier Detection:**\n",
        "\n",
        "Outliers are extreme or odd values lies far outside the general “pattern” or distribution in the dataset.\n",
        "\n",
        "They distort/skew data resulting in less accuracy of the model.\n",
        "\n",
        "We can identify outlier visually using boxplots/scatter plots and statistically using IQR method/z-score.\n",
        "\n",
        "\n",
        "Justification: From the univariate analysis, only the below attributes are identified with variable values, whereas the rest of the attributes are either 0s or binary values (0,1). Hence selecting the below attributes for outlier analysis.\n",
        "*   Age\n",
        "*   Number of Sexual Partners\n",
        "*   Number of Pregnancies\n",
        "*   First Sexual encounter\n",
        "*   Hormonal Contraceptives(Years)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DU1KAmoANodo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "#fig, a = plt.subplots(15, 2, figsize=(18, 55))\n",
        "columns = ['Age', 'Number of sexual partners', 'First sexual intercourse','Num of pregnancies','Hormonal Contraceptives (years)']\n",
        "for i, col in enumerate(columns, 1):\n",
        "    plt.subplot(5, 1, i)\n",
        "    plt.boxplot(df[col].dropna(), vert=False, patch_artist=True,\n",
        "            boxprops=dict(facecolor='lightblue', color='navy'),\n",
        "            medianprops=dict(color='red', linewidth=2),\n",
        "            whiskerprops=dict(color='navy'),\n",
        "            capprops=dict(color='navy'),\n",
        "            flierprops=dict(marker='o', color='darkorange', markersize=8))\n",
        "    plt.title(col)\n",
        "\n",
        "plt.suptitle(\"Outlier Detection in Numeric Features\",y=0.98,va='top', fontsize=16)\n",
        "plt.tight_layout(pad=3.0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H5NB-FNcOiqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference:**\n",
        "\n",
        "Based on the boxplot charts, we can infer that there are outliers in the identified columns.\n",
        "\n",
        "We are using capping to limit the values for 2 columns:\n",
        "\n",
        "a) Number of sexual partners: 28 seems extreme and could be data entry anomaly.\n",
        "\n",
        "b) First sexual intercourse: 32 is removed as it is rare."
      ],
      "metadata": {
        "id": "IZ2P4DS_0znr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3: Skew Analysis:**\n",
        "\n"
      ],
      "metadata": {
        "id": "D9Gd7NRYZUrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skewness = df[columns].skew().sort_values(ascending=False)\n",
        "print(\"Feature skewness:\")\n",
        "print(skewness)"
      ],
      "metadata": {
        "id": "IUP2948w2c4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the skew analysis, we can identify that all the given attributes are highly skewed.\n",
        "\n",
        "This matches what we saw in the outlier analysis, the skew is driven by those extreme high values.\n",
        "\n",
        "We can perform transformation and capping to reduce the skewness."
      ],
      "metadata": {
        "id": "aHgtCMjXAuUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #Capping the values for Number of sexual partners and first sexual partner\n",
        "# capped_cols_values = {'Number of sexual partners': 15, 'First sexual intercourse': 10}\n",
        "\n",
        "#First sexual intercourse\n",
        "Q1 = df['First sexual intercourse'].quantile(0.25)\n",
        "Q3 = df['First sexual intercourse'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "df['First sexual intercourse'] = np.where(df['First sexual intercourse'] < lower_bound, lower_bound, df['First sexual intercourse'])\n",
        "\n",
        "# #Number of sexual partners\n",
        "df['Number of sexual partners'] = np.where(df['Number of sexual partners'] > 15.0, 15.0, df['Number of sexual partners'])\n",
        "\n",
        "#Hormonal Contraceptives (years)\n",
        "df['Hormonal Contraceptives (years)'] = np.where(df['Hormonal Contraceptives (years)'] > 30.0, 3.0, df['Hormonal Contraceptives (years)'])\n",
        "\n",
        "# Perform log transformation on columns:\n",
        "for col in columns:\n",
        "    if col != 'Biopsy':\n",
        "      df[col] = np.log1p(df[col])\n",
        "#df['Hormonal Contraceptives (years)'] = np.log1p(df['Hormonal Contraceptives (years)'])\n",
        "\n",
        "skewness = df[columns].skew().sort_values(ascending=False)\n",
        "print(\"Feature skewness after capping and transformation:\")\n",
        "print(skewness)"
      ],
      "metadata": {
        "id": "4mORXvVW1zZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post transformation, the skewness has reduced"
      ],
      "metadata": {
        "id": "epOf6AeyE7fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.4: Standardisation or Normalization:**"
      ],
      "metadata": {
        "id": "EsaNDeDzFDPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "num_cols = num_cols.drop('Biopsy')\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])"
      ],
      "metadata": {
        "id": "xwen8yePBAQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.5: Feature Engineering:**"
      ],
      "metadata": {
        "id": "n8zzPyEyFia9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif\n",
        "\n",
        "X = df.drop(columns=['Biopsy'])\n",
        "y = df['Biopsy']\n",
        "\n",
        "\n",
        "# ----- Step 1: Variance Threshold -----\n",
        "selector = VarianceThreshold(threshold=0.01)\n",
        "X_var = selector.fit_transform(X)\n",
        "X_var_df = pd.DataFrame(X_var, columns=X.columns[selector.get_support()])\n",
        "\n",
        "# ----- Step 2: Correlation Filtering -----\n",
        "corr_matrix = X_var_df.corr().abs()\n",
        "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [col for col in upper_tri.columns if any(upper_tri[col] > 0.85)]\n",
        "X_corr = X_var_df.drop(columns=to_drop)\n",
        "\n",
        " # ----- Step 3: Mutual Information Ranking -----\n",
        "mi = mutual_info_classif(X_corr, y, random_state=42)\n",
        "mi_series = pd.Series(mi, index=X_corr.columns).sort_values(ascending=False)\n",
        "\n",
        "    # Select top_k features\n",
        "top_features = mi_series.head(10).index\n",
        "#X_selected = X_corr[top_features]\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "mi_series.head(10).plot(kind='barh')\n",
        "plt.title(\"Top 10 Important Features for Biopsy Prediction\")\n",
        "plt.xlabel(\"Feature Importance Score\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6TqwsGjw-gsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Model Building:**"
      ],
      "metadata": {
        "id": "LQIt2Z-aI0PM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X = df[top_features]\n",
        "y = df['Biopsy']  # Use original binary target\n",
        "\n",
        "# Split data into train and test\n",
        "\n",
        "(X_train, X_test, y_train, y_test) = train_test_split(X, y, stratify=y,test_size= 0.2)\n",
        "\n",
        "# testing size = 20 %\n",
        "# rest 80 % is used for training\n",
        "# stratify parameter ensures that observations from each class is are given equal weightage\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "fit_result = {}"
      ],
      "metadata": {
        "id": "JALZ8T68JB7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1. Logistic Regression:**"
      ],
      "metadata": {
        "id": "qWSkXRneJqrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "grid_lr = GridSearchCV(LogisticRegression(class_weight='balanced', max_iter=500),\n",
        "                       param_grid_lr, cv=5, scoring='f1')\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "lr_result_df = pd.DataFrame(grid_lr.cv_results_)\n",
        "\n",
        "\n",
        "best_lr = grid_lr.best_estimator_\n",
        "print(f\"The best fit params selected are \\n C:{best_lr.get_params()['C']}, \\n solver:{best_lr.get_params()['solver']} \")\n",
        "#logistic_model = LogisticRegression(solver='liblinear', class_weight='balanced') # default classfier\n",
        "\n",
        "#logistic_model.fit(X_train,y_train)\n",
        "\n",
        "# predict values for the test data\n",
        "y_predict_logisticRegression  = best_lr.predict(X_test)\n",
        "\n",
        "y_prob_logisticRegression = best_lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fit_result['Logistic Regression'] = [y_predict_logisticRegression , y_prob_logisticRegression]"
      ],
      "metadata": {
        "id": "XbtkDsGTJugZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2. Decision Tree:**"
      ],
      "metadata": {
        "id": "T7ursKre5yp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_dt = {\n",
        "    'max_depth': [3, 5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "grid_dt = GridSearchCV(DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
        "                       param_grid_dt, cv=5, scoring='f1')\n",
        "grid_dt.fit(X_train, y_train)\n",
        "best_dt = grid_dt.best_estimator_\n",
        "\n",
        "# predict values for the test data\n",
        "y_predict_decisionTree  = best_dt.predict(X_test)\n",
        "\n",
        "y_prob_decisionTree = best_dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fit_result['Decision Tree'] = [y_predict_decisionTree,  y_prob_decisionTree]"
      ],
      "metadata": {
        "id": "jh1OtSFN5yU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3. K-Nearest Neighbour**"
      ],
      "metadata": {
        "id": "BPSj3-3h6Oiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 11],\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(),\n",
        "                        param_grid_knn, cv=5, scoring='f1')\n",
        "grid_knn.fit(X_train, y_train)\n",
        "best_knn = grid_knn.best_estimator_\n",
        "# predict values for the test data\n",
        "y_predict_knn  = best_knn.predict(X_test)\n",
        "\n",
        "y_prob_knn = best_knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fit_result['KNN'] = [y_predict_knn, y_prob_knn]"
      ],
      "metadata": {
        "id": "mTnNgOBi6l22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.4. Ensemble - RandomForest**"
      ],
      "metadata": {
        "id": "NaxgqihP6tGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(class_weight='balanced', random_state=42),\n",
        "                       param_grid_rf, cv=5, scoring='f1')\n",
        "grid_rf.fit(X_train, y_train)\n",
        "best_rf = grid_rf.best_estimator_\n",
        "# predict values for the test data\n",
        "y_predict_rf  = best_rf.predict(X_test)\n",
        "\n",
        "y_prob_rf = best_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fit_result['Random Forest'] = [y_predict_rf,y_prob_rf]"
      ],
      "metadata": {
        "id": "D182UfKV6zVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Model Evaluation**"
      ],
      "metadata": {
        "id": "VITiDjkynDcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score"
      ],
      "metadata": {
        "id": "92Id-Gtin747"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for model, model_result in fit_result.items():\n",
        "    y_pred, y_prob = model_result\n",
        "    results.append({\n",
        "        \"Model\": model,\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred),\n",
        "        \"ROC-AUC\": roc_auc_score(y_test, y_prob)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "dASgHU_O_Q6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 3x2 grid (6 slots). We'll use 5: 4 metrics + 1 ROC curve\n",
        "fig, axes = plt.subplots(3, 2, figsize=(14, 16))\n",
        "axes = axes.flatten()\n",
        "\n",
        "metrics = [\"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\"]\n",
        "\n",
        "# Plot metric comparison bar charts\n",
        "plt.suptitle('Model Evaluation metrics', y=1.0,va='top',fontsize=20)\n",
        "for i, metric in enumerate(metrics):\n",
        "    results_df.plot(\n",
        "        x=\"Model\", y=metric, kind=\"bar\", ax=axes[i], legend=False, color=\"skyblue\"\n",
        "    )\n",
        "    axes[i].set_title(f\"{metric} Comparison\")\n",
        "    axes[i].set_ylabel(metric)\n",
        "    axes[i].set_ylim(0, 1)\n",
        "\n",
        "# ROC Curve (all models together in one subplot)\n",
        "ax = axes[4]\n",
        "for model, model_result in fit_result.items():\n",
        "    y_pred, y_prob = model_result\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    auc_score = roc_auc_score(y_test, y_prob)\n",
        "    ax.plot(fpr, tpr, label=f\"{model} (AUC = {auc_score:.2f})\")\n",
        "\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_title(\"ROC Curve Comparison\")\n",
        "ax.set_xlabel(\"False Positive Rate\")\n",
        "ax.set_ylabel(\"True Positive Rate (Recall)\")\n",
        "ax.legend()\n",
        "\n",
        "# Remove the unused last subplot (axes[5])\n",
        "fig.delaxes(axes[5])\n",
        "\n",
        "\n",
        "plt.tight_layout(pad=2.0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SAGne5fYWPQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.1. Detailed Model Performance Analysis**\n",
        "\n",
        "In this section, we will conduct a comprehensive evaluation of all trained models to identify the best performer for cervical cancer prediction.\n",
        "\n",
        "**Key Evaluation Criteria:**\n",
        "- **Recall (Sensitivity)**: Most critical metric for medical diagnosis - minimizing false negatives\n",
        "- **Precision**: Important for resource allocation - avoiding excessive false positives  \n",
        "- **F1-Score**: Balanced measure combining precision and recall\n",
        "- **ROC-AUC**: Overall discriminative ability of the model\n",
        "\n",
        "**Medical Context Consideration:**\n",
        "In cancer detection, missing a positive case (false negative) is more dangerous than a false alarm (false positive). Therefore, we prioritize models with high recall while maintaining reasonable precision."
      ],
      "metadata": {
        "id": "3qQTz7udhAZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Performance Evaluation with Additional Metrics\n",
        "from sklearn.metrics import (confusion_matrix, classification_report,\n",
        "                           accuracy_score, balanced_accuracy_score,\n",
        "                           matthews_corrcoef, average_precision_score)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create comprehensive results dataframe\n",
        "enhanced_results = []\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE MODEL PERFORMANCE EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for model_name, model_result in fit_result.items():\n",
        "    y_pred, y_prob = model_result\n",
        "\n",
        "    # Calculate all metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "    avg_precision = average_precision_score(y_test, y_prob)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "    # Confusion matrix components\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    enhanced_results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Balanced_Accuracy\": balanced_acc,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"Specificity\": specificity,\n",
        "        \"F1_Score\": f1,\n",
        "        \"ROC_AUC\": roc_auc,\n",
        "        \"Avg_Precision\": avg_precision,\n",
        "        \"MCC\": mcc,\n",
        "        \"True_Positives\": tp,\n",
        "        \"False_Positives\": fp,\n",
        "        \"True_Negatives\": tn,\n",
        "        \"False_Negatives\": fn\n",
        "    })\n",
        "\n",
        "    print(f\"\\n{model_name} Performance:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall: {recall:.4f}\")\n",
        "    print(f\"  F1-Score: {f1:.4f}\")\n",
        "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
        "    print(f\"  Confusion Matrix: TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
        "\n",
        "# Create enhanced results dataframe\n",
        "enhanced_results_df = pd.DataFrame(enhanced_results)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY TABLE - ALL METRICS\")\n",
        "print(\"=\"*80)\n",
        "print(enhanced_results_df.round(4))"
      ],
      "metadata": {
        "id": "TLJUAn1JhJQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create comprehensive visualization for model comparison\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# Key metrics for medical diagnosis\n",
        "key_metrics = ['Precision', 'Recall', 'F1_Score', 'ROC_AUC', 'Balanced_Accuracy', 'MCC']\n",
        "\n",
        "# Create subplots for different metric comparisons\n",
        "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
        "fig.suptitle('Comprehensive Model Performance Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot individual metrics\n",
        "for i, metric in enumerate(key_metrics):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    ax = axes[row, col]\n",
        "\n",
        "    # Bar plot for each metric\n",
        "    bars = ax.bar(enhanced_results_df['Model'], enhanced_results_df[metric],\n",
        "                  color=['lightblue', 'lightgreen', 'lightcoral', 'lightyellow'])\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    ax.set_title(f'{metric.replace(\"_\", \" \")}', fontweight='bold')\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Confusion Matrix Heatmap\n",
        "ax = axes[2, 0]\n",
        "confusion_data = enhanced_results_df[['Model', 'True_Positives', 'False_Positives', 'True_Negatives', 'False_Negatives']]\n",
        "cm_matrix = confusion_data.set_index('Model').T\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "ax.set_title('Confusion Matrix Components', fontweight='bold')\n",
        "\n",
        "# ROC Curves Comparison\n",
        "ax = axes[2, 1]\n",
        "for model_name, model_result in fit_result.items():\n",
        "    y_pred, y_prob = model_result\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    auc_score = roc_auc_score(y_test, y_prob)\n",
        "    ax.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f})', linewidth=2)\n",
        "\n",
        "ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('ROC Curves Comparison', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Model Ranking Summary\n",
        "ax = axes[2, 2]\n",
        "# Create ranking based on key metrics (weighted by importance in medical context)\n",
        "weights = {'Recall': 0.4, 'F1_Score': 0.3, 'ROC_AUC': 0.2, 'Precision': 0.1}\n",
        "enhanced_results_df['Weighted_Score'] = sum(enhanced_results_df[metric] * weight\n",
        "                                           for metric, weight in weights.items())\n",
        "\n",
        "ranking = enhanced_results_df.sort_values('Weighted_Score', ascending=False)\n",
        "bars = ax.barh(ranking['Model'], ranking['Weighted_Score'],\n",
        "               color=['gold', 'silver', '#CD7F32', 'lightgray'])\n",
        "\n",
        "# Add value labels\n",
        "for i, bar in enumerate(bars):\n",
        "    width = bar.get_width()\n",
        "    ax.text(width + 0.01, bar.get_y() + bar.get_height()/2.,\n",
        "            f'{width:.3f}', ha='left', va='center', fontweight='bold')\n",
        "\n",
        "ax.set_xlabel('Weighted Performance Score')\n",
        "ax.set_title('Overall Model Ranking\\n(Weighted by Medical Importance)', fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print ranking\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL RANKING (Weighted by Medical Importance)\")\n",
        "print(\"Weights: Recall=40%, F1=30%, ROC-AUC=20%, Precision=10%\")\n",
        "print(\"=\"*60)\n",
        "for i, row in ranking.iterrows():\n",
        "    print(f\"{ranking.index.get_loc(i)+1}. {row['Model']}: {row['Weighted_Score']:.4f}\")"
      ],
      "metadata": {
        "id": "wGjqnb5IhMmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed Confusion Matrix Analysis for Each Model\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Detailed Confusion Matrix Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "model_names = list(fit_result.keys())\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (model_name, model_result) in enumerate(fit_result.items()):\n",
        "    y_pred, y_prob = model_result\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Create heatmap\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
        "                xticklabels=['No Cancer', 'Cancer'],\n",
        "                yticklabels=['No Cancer', 'Cancer'])\n",
        "\n",
        "    axes[i].set_title(f'{model_name}\\nConfusion Matrix', fontweight='bold')\n",
        "    axes[i].set_xlabel('Predicted Label')\n",
        "    axes[i].set_ylabel('True Label')\n",
        "\n",
        "    # Add performance text\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    # Add text box with key metrics\n",
        "    textstr = f'Sensitivity: {sensitivity:.3f}\\nSpecificity: {specificity:.3f}\\nFN (Missed): {fn}\\nFP (False Alarm): {fp}'\n",
        "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
        "    axes[i].text(0.02, 0.98, textstr, transform=axes[i].transAxes, fontsize=9,\n",
        "                verticalalignment='top', bbox=props)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Medical Impact Analysis\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MEDICAL IMPACT ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for model_name, model_result in fit_result.items():\n",
        "    y_pred, y_prob = model_result\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"  • Correctly identified cancer cases (True Positives): {tp}\")\n",
        "    print(f\"  • Missed cancer cases (False Negatives): {fn} ⚠️\")\n",
        "    print(f\"  • False alarms (False Positives): {fp}\")\n",
        "    print(f\"  • Correctly identified healthy cases (True Negatives): {tn}\")\n",
        "\n",
        "    if fn > 0:\n",
        "        print(f\"  • ⚠️  WARNING: {fn} cancer cases would be MISSED by this model!\")\n",
        "    if fp > 10:  # Arbitrary threshold\n",
        "        print(f\"  • ⚠️  NOTE: {fp} unnecessary follow-ups due to false alarms\")\n",
        "\n",
        "    # Calculate cost implications (hypothetical)\n",
        "    missed_cost = fn * 10000  # High cost for missing cancer\n",
        "    false_alarm_cost = fp * 500  # Lower cost for unnecessary tests\n",
        "    total_cost = missed_cost + false_alarm_cost\n",
        "    print(f\"  • Estimated cost impact: ${total_cost:,} (${missed_cost:,} from missed cases + ${false_alarm_cost:,} from false alarms)\")"
      ],
      "metadata": {
        "id": "vza0EFXChPZE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}